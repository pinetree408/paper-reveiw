## Title : Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations

### Abstract

Minsinterpretation and abuse of statistical test, confidence intervals, and statistical power have been decired for decades, yet remain rampant. A key problem is that there are no interpretations for these concepts that are at once simple, intuitive, correct, and foolproof. Instead, correct use and interpretation of these statistics requires an attention to detail which seems to tax the patience of working scientists. This high cognitive demand has led to an epidemic of shortcut definitions and interpretations that are simply wrong, sometimes disastrously soâ€”and yet these misinterprestations dominate much of the scientific literature. In light of this problem, we provide definitions and a discussion of basic statics that are more general and critical than typically found in traditional introductory expositions. Our goal is to provide a resource for instructors, researchers, and consumers of statistics whose knowledge of statistical theory and technique may be limited but who wish to avoid and spot misinterpretations. We emphasize how violation of often unstated analysis protocols (such as selecting analyses for presentation based on the P values they produce) can lead to small P values even if the declared test hypothesis is correct, and can lead to large P values even if that hypothesis is incorrect. We then provide an explanatory list of 25 misinterpretations of P values, confidence intervals, and power. We conclude with guidelines for improving statistical interpretation and reporting.

### Introduction

Misinterpretation and abuse of statistical tests has been decried for decades, yet remains so rampant that  some scientific journals discourage use of "statistical significance " (classifying results as "significant" or not based on a P value).

### Common misinterpretations of single P values

1. The P value is the probability that the test hypothesis is true; for example, if a test of the null hypothesis gave P = 0.01, the null hypothesis has only a 1% chance of being ture; if 



